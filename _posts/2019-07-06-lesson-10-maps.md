---
layout: post
published: true
title: 'Lesson 10/11: Maps!'
date: '2019-06-10'
---
Things are a bit of a mess at this point, because of the sheer lack of power that is known as my laptop.  But thanks to a bunch of other people (Gabriele, Berni, Daniel in particular) I got some stuff off the ground.

This was the way to get the TGN numbers.

      import re, os


      #A first attempt that didn't pan out the way I wanted it to.
      #dicFreq = {}

      #for i in listOfResults:
       #   if f.startswith("dltext"): # fileName test
        #      with open(source + f, "r", encoding="utf8") as f1:
         #         text = f1.read()
      #
       ##          date = re.search(r'<date value="([\d-]+)"', text).group(1)
      #
       #           c = 0 # item counter
        #          for s in split[1:]:
         #             c += 1
          #            s = "<div3 " + s # a step to restore the integrity of items
           #           #input(s)
            #          regtgn = re.search(r'authname="tgn,\d\d\d\d\d\d\d)
      #
       #               # generating necessary bits
        #              dateVar   = date
      #
       #               # creating a text variable
        #              var = "\t".join([date,regtgn])
         #             #input(var)
      #
       #               ourCSV.append(var)
      #
      #
       ##      if counter % 100 == 0:
         #         print(counter)
      #
      ## saving
      #with open("dispatch_map_as_TSV.csv", "w", encoding="utf8") as f9:
       #   f9.write("\n".join(ourCSV))
      #print(counter)

      #Where the XMLs are saved
      source = "C:/Users/Liam/Documents/School/GradSchool/DHMethods/Lesson08/betterdispatch/"

      #Where the files will be written
      target = "C:/Users/Liam/Documents/School/GradSchool/DHMethods/Lesson10/tgnstuff/"


      lof = os.listdir(source)
      counter = 0 # general counter to keep track of the progress

      #Define a function that takes one conditions, a filter
      def generate(filter):

      #establish an empty list
          topCountDictionary = {}

      #print out what year you're working on
          print(filter)
          #establish a counter
          counter = 0
          #start a loop of files in a list thereof
          for f in lof:
              #check if the name is what we're looking for, gets rid of garbage that might be around
              if f.startswith("dltext"):
                  #open a file with a specified coding        
                  with open(source + f, "r", encoding="utf8") as f1:
                      #text is established as contents of the file
                      text = f1.read()

                      #clean up text a bit by putting & in properly
                      text = text.replace("&amp;", "&")

                      # try to find the date
                      date = re.search(r'<date value="([\d-]+)"', text).group(1)
                      #print(date)

                      #restrict files in question to the correct date
                      if date.startswith(filter):
                          #a new loop of topographical info in text
                          for tg in re.findall(r"(tgn,\d+)", text):
                              #split on commas
                              tgn = tg.split(",")[1]

                              #if TGN already exists in list, add a tally
                              if tgn in topCountDictionary:
                                  topCountDictionary[tgn] += 1
                              #otherwise put it in the list and set it equal to one
                              else:
                                  topCountDictionary[tgn]  = 1

                              #input(topCountDictionary)
          #establish a TSV                    
          top_TSV = []

          #work your way through topCountDictionary
          for k,v in topCountDictionary.items():
              val = "%09d\t%s" % (v, k)
              #input(val)
              #append value to TSV
              top_TSV.append(val)                    

          # saving
          #write a header
          header = "freq\ttgn\n"
          #write to this location
          with open(target+"dispatch_toponyms_%s.tsv" % filter, "w", encoding="utf8") as f9:
              f9.write(header+"\n".join(top_TSV))
          #print(counter)

      #generate("186")

      generate("1861")
      generate("1862")
      generate("1863")
      generate("1864")
      generate("1865")
      
 And then to sort the TGN XML files
 
       import re, os

      #This is where I hide my files.  I really need to reorganize.
      source = "C:/Users/Liam/Documents/School/GradSchool/DHMethods/Lesson10/TGN"
      #Where the files will be written
      target = "C:/Users/Liam/Documents/School/GradSchool/DHMethods/Lesson10/tgnstuff/"

      #we're defining a function here and giving it one parameter.  That parameter is the TGN XML locaiton
      def generateTGNdata(source):
          #make a list of files in the source
          lof = os.listdir(source)
          #let's make a bunch of things. A list of successful places, a list of failed
          tgnList = []
          tgnListNA = []
          #...and a counter! always a counter
          count = 0

          #for every file in the list we created earlier (a handy loop)
          for f in lof:
              #test the files for usefulness, who knows what other garbage is in that folder
              if f.startswith("TGN"): # fileName test
                  #print out the filename
                  print(f)
                  #open that puppy up and make the variable data the contents of the file
                  with open(source+f, "r", encoding="utf8") as f1:
                      data = f1.read()

                      #split this badboy on the XML tag Subject
                      data = re.split("</Subject>", data)

                      #loop through the data, swap out new lines as they cause a mess
                      for d in data:
                          d = re.sub("\n +", "", d)
                          #print(d)

                          #we're trying to isolate the actual locations from a long list of other things.
                          if "Subject_ID" in d:
                              # SUBJECT ID
                              #following the XML tag for Subject ID gets us the TGN number
                              placeID = re.search(r"Subject_ID=\"(\d+)\"", d).group(1)
                              #print(placeID)

                              # NAME OF THE PLACE
                              #here we fish out the actual info on the name of the location
                              placeName = re.search(r"<Term_Text>([^<]+)</Term_Text>", d).group(1)
                              #print(placeName)

                              # COORDINATES
                              #we're extracting coordinates here.  Unfortunately, TGN doesn't give seconds in its coordinates, so everything is a bit rough.
                              if "<Coordinates>" in d:
                                  #we used the XML tag to find the coordinates, but they're stored in different lines, so we're putting everything together.
                                  latGr = re.search(r"<Latitude>(.*)</Latitude>", d).group(1)
                                  lat = re.search(r"<Decimal>(.*)</Decimal>", latGr).group(1)

                                  lonGr = re.search(r"<Longitude>(.*)</Longitude>", d).group(1)
                                  lon = re.search(r"<Decimal>(.*)</Decimal>", lonGr).group(1)
                                  #print(lat)
                                  #print(lon)
                              #if things didn't work out above, give a good old NA
                              else:
                                  lat = "NA"
                                  lon = "NA"

                              #append out new info to a list divided by tabs
                              tgnList.append("\t".join([placeID, placeName, lat, lon]))
                              #input(tgnList)

                              #how to handle non-locations
                              if lat == "NA":
                                  #print("\t"+ "; ".join([placeID, placeName, lat, lon]))
                                  tgnListNA.append("\t".join([placeID, placeName, lat, lon]))

          # saving
          #create a header as the first line of 
          header = "tgnID\tplacename\tlat\tlon\n"

          #write this to a TSV file in the target location by joining the entries of the list we created
          with open(target+"tgn_data_light.tsv", "w", encoding="utf8") as f9a:
               f9a.write(header+"\n".join(tgnList))

          #another file of places with no coordinaes
          with open(target+"tgn_data_light_NA.tsv", "w", encoding="utf8") as f9b:
               f9b.write(header+"\n".join(tgnListNA))

          #print("TGN has %d items" % len(tgnList))
      #and then run this puppy!
      generateTGNdata(source)

      #most of my python files are [filename]pup.py
      
   ...But my computer runs out of memory while doing this.  I know, I know, figure out a way to work around it.  But the real work around at this point is a new computer.  Usually it could process a couple XMLs before running out of memory, but sometimes not even that.  He's an old dog.
   
   Fortunately, Gabriele sent me her files of location/frequency by year, which I was able to plot in QGIS and make a little GIF of.
   
   ![giphy.gif]({{site.baseurl}}/img/giphy.gif)
   
   I focused on the US of A because a) the majority of places named were within the states and b) zooming out to a global level lost the level of detail to actually see anything.  Interesting to see the changing frequencies as they move around the map.  I will endeavor to actually get a smaller time increment and see how that works, but for now I'm happy to have had any form of success.
   
   There was some oddity with matching the CRSs of the background map and the data, but ultimately ironed it out.  Also of note: the TNG locations for some things are hilariously bad.  That blob in the middle of the US is the TGN location of America, for example.  Silly!
